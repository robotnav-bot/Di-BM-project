<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Learning Diverse Skills for Behavior Models with Mixture of Experts.">
  <meta name="keywords" content="Navigation, World Models, Robotics, 3D U-Net, Diffusion Policies">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learning Diverse Skills for Behavior Models with Mixture of Experts</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Learning Diverse Skills for Behavior Models with Mixture of Experts</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=fy3BKH4AAAAJ&hl">Wangtian Shen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=GSVkVZ0AAAAJ">Jinming Ma</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="#">Mingliang Zhou</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=70Fly6cAAAAJ">Ziyang Meng</a><sup>1 *</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <p>
            <span class="author-block"><sup>1</sup>Department of Precision Instrument, Tsinghua University,</span>
            </p>
            <p>
            <span class="author-block"><sup>2</sup>Xiaomi Robotics Lab, Beijing, China</span>
            </p>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2601.12397" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2601.12397" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/robotnav-bot/Di-BM" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img src="./static/images/intro_1.png" alt="Overview" style="width: 30%;">
          <h2 class="subtitle has-text-centered" style="margin-top: 15px;">
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Imitation learning has demonstrated strong performance in robotic manipulation by learning from large-scale human demonstrations. While existing models excel at single-task learning, it is observed in practical applications that their performance degrades in the multi-task setting, where interference across tasks leads to an averaging effect. To address this issue, we propose to learn diverse skills for behavior models with Mixture of Experts, referred to as <strong>Di-BM</strong>. Di-BM associates each expert with a distinct observation distribution, enabling experts to specialize in sub-regions of the observation space.  
Specifically, we employ energy-based models to represent expert-specific observation distributions and jointly train them alongside the corresponding action models.
Our approach is plug-and-play and can be seamlessly integrated into standard imitation learning methods. Extensive experiments on multiple real-world robotic manipulation tasks demonstrate that Di-BM significantly outperforms state-of-the-art baselines. Moreover, fine-tuning the pretrained Di-BM on novel tasks exhibits superior data efficiency and the reusable of expert-learned knowledge.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <img src="./static/images/overview-new.png" alt="Overview" style="width: 100%;">
          <h2 class="subtitle has-text-centered is-size-6" style="margin-top: 15px; font-weight: normal;">
            We propose <strong>Di-BM</strong> - Diverse skill learning for Behavior Models designed to acquire primitive skills from multi-task datasets. By leveraging EBM-based observation distributions together with a gating network, Di-BM automatically allocates experts to its preferred domain.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">System Architecture</h2>
        <div class="content has-text-justified">
        </div>
        <div class="content has-text-justified">
          <p>
            Our system introduces a shortcut-based one-step generation paradigm for navigation world model. Unlike traditional diffusion models that require expensive iterative denoising, our world model directly predicts a sequence of 11 future frames in a single step. We utilize a 3D U-Net backbone operating within a VAE latent space. To handle high-dimensional video data efficiently, we employ a hybrid CNN-Transformer architecture with decoupled spatial and temporal attention. Specifically, a window-based temporal attention mechanism allows the model to capture complex dynamics without the quadratic complexity of full global attention. We integrate this lightweight world model into a model-based planning framework using the Cross-Entropy Method (CEM). To ensure robust performance under limited computational budgets (small sample size), we propose an anchor-based initialization strategy. Instead of random sampling, this approach initializes candidate trajectories using fixed velocity priors, significantly improving the planner's efficiency and success rate across multi-modal tasks (Image, Language, and Point goals).
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Simulation Experiments</h2>
        <div class="content has-text-justified">
          <p>
            We conduct experiments in the RoboTwin simulator and present the visualizations here. The right side of the video displays the real-time variation in the selection probability of each expert as the task progresses. It can be observed that different experts are assigned to different stages of various tasks, demonstrating that they have mastered distinct skills.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/0.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/1.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/2.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/3.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/4.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/5.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/6.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/7.mp4" type="video/mp4">
        </video>
      </div>
    </div>
    
    <div class="columns is-centered">
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/6.mp4" type="video/mp4">
        </video>
      </div>
      <div class="column is-half">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/7.mp4" type="video/mp4">
        </video>
      </div>
    </div>
    
    <div class="columns is-centered has-text-centered" style="margin-top: 20px;">
      <div class="column is-full-width">
        <img src="./static/images/table1.png" alt="Simulation Results Table" style="width: 100%;">
      </div>
    </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Real-World Experiments</h2>
        <div class="content has-text-justified">
          <p>
            We conduct experiments in the real-world with Nova5 robot arm and evaluate our method on 9 real-world manipulation tasks.
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <video autoplay controls muted loop playsinline width="100%">
          <source src="./static/videos/realworld.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="columns is-centered has-text-centered" style="margin-top: 20px;">
      <div class="column is-full-width">
          <img src="./static/images/table3.png" alt="Simulation Results Table" style="width: 100%;">
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Advantage In Post-training</h2>
        <div class="content has-text-justified">
          <p>
            Building on the hypothesis that each expert in Di-BM specializes in a subset of primitive skills, we expect the pretrained Di-BM to adapt more efficiently to unseen tasks through post-training.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered" style="margin-top: 20px;">
      <div class="column is-full-width">
        <img src="./static/images/fig5.png" alt="Simulation Results Table" style="width: 100%;">
      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{shen2026learningdiverseskillsbehavior,
      title={Learning Diverse Skills for Behavior Models with Mixture of Experts}, 
      author={Wangtian Shen and Jinming Ma and Mingliang Zhou and Ziyang Meng},
      year={2026},
      eprint={2601.12397},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2601.12397}, 
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/pdf/2601.12397">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/robotnav-bot/Di-BM" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template was adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>